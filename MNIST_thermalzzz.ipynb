{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jingyi-Z/ThermalZZZ/blob/main/MNIST_thermalzzz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11/13/25 Original Version\n"
      ],
      "metadata": {
        "id": "ACzzRPuF4J6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna -q\n",
        "! pip install xlsxwriter\n",
        "! rm -rf ThermalZZZ\n",
        "! git clone https://github.com/Jingyi-Z/ThermalZZZ.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5868e9c5-1ef9-404a-fd8e-0f54b5d59a0e",
        "id": "QCOR-lFS5Hgu"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.9\n",
            "Cloning into 'ThermalZZZ'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 719.45 KiB | 11.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from importlib_resources import files, as_file\n",
        "from openpyxl import load_workbook\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "from typing import Literal, Optional, Union\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from numpy.linalg import matrix_rank\n",
        "import secrets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,confusion_matrix, accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader,Subset,TensorDataset\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import os\n",
        "\n",
        "from pylab import *\n",
        "import xlsxwriter\n",
        "from tkinter.filedialog import askopenfilename\n",
        "import matplotlib.font_manager as fm\n",
        "import optuna\n",
        "import json, csv, time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "USE_PIN_MEMORY = torch.cuda.is_available()\n",
        "data_path = '/content/ThermalZZZ/Data_thermalzzz.xlsx'\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "mpl.rcParams.update({\n",
        "    \"figure.dpi\": 120,\n",
        "    \"savefig.dpi\": 600,\n",
        "    \"savefig.transparent\": True,\n",
        "    \"font.size\": 9.5,\n",
        "    \"font.family\": 'DejaVu Sans',\n",
        "    \"mathtext.fontset\": \"dejavusans\",\n",
        "    \"axes.linewidth\": 0.9,\n",
        "    \"axes.labelsize\": 10,\n",
        "    \"xtick.direction\": \"in\",\n",
        "    \"ytick.direction\": \"in\",\n",
        "    \"xtick.major.size\": 4,\n",
        "    \"xtick.minor.size\": 2.5,\n",
        "    \"ytick.major.size\": 4,\n",
        "    \"ytick.minor.size\": 2.5,\n",
        "    \"legend.frameon\": True,\n",
        "    \"legend.facecolor\": \"none\",\n",
        "    \"legend.edgecolor\": \"0.85\",\n",
        "    \"legend.framealpha\": 0.95,\n",
        "    \"legend.fontsize\": 8.5,\n",
        "})\n"
      ],
      "metadata": {
        "id": "nTkBSw0UBOD7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voltage pulse-temperature mapping"
      ],
      "metadata": {
        "id": "2BRTWzvvceiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 pulse -> 4 Temp"
      ],
      "metadata": {
        "id": "KpgATh_ScnWE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_P3xse8cvPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 pulse -> 20 Temp"
      ],
      "metadata": {
        "id": "wD4rwoSXcwH0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ixNwgjXocvmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Original ICGS"
      ],
      "metadata": {
        "id": "jlkGiqJh5tHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log\n",
        "# LOG_DIR = \"/content/drive/MyDrive/oicgs_logs\" # Log in Drive\n",
        "LOG_DIR = \"/content/logs\" # Log in Colab\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "LOG_PATH = os.path.join(LOG_DIR, \"ICGS_update_log.csv\")  # single rolling log\n",
        "\n",
        "def _to_scalar(x):\n",
        "    \"\"\"Best-effort: convert tensors/ndarrays/scalars to plain python scalars if size==1.\"\"\"\n",
        "    try:\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            if x.numel() == 1:\n",
        "                return x.detach().cpu().item()\n",
        "            return f\"<Tensor shape={tuple(x.shape)} dtype={x.dtype}>\"\n",
        "        if isinstance(x, np.ndarray):\n",
        "            if x.size == 1:\n",
        "                return x.item()\n",
        "            return f\"<ndarray shape={x.shape} dtype={x.dtype}>\"\n",
        "        if isinstance(x, (np.floating, np.integer)):\n",
        "            return x.item()\n",
        "        return x\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "def sanitize_params(p: dict):\n",
        "    \"\"\"Make params JSON-serializable without dumping huge arrays.\"\"\"\n",
        "    out = {}\n",
        "    for k, v in p.items():\n",
        "        if isinstance(v, (int, float, str, bool)) or v is None:\n",
        "            out[k] = v\n",
        "        elif isinstance(v, (np.ndarray, torch.Tensor)):\n",
        "            # store a compact description instead of full data\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                out[k] = f\"<Tensor shape={tuple(v.shape)} dtype={v.dtype}>\"\n",
        "            else:\n",
        "                out[k] = f\"<ndarray shape={v.shape} dtype={v.dtype}>\"\n",
        "        else:\n",
        "            # try scalar conversion, otherwise repr\n",
        "            sv = _to_scalar(v)\n",
        "            out[k] = sv if isinstance(sv, (int, float, str, bool)) or sv is None else repr(v)\n",
        "    return out\n",
        "\n",
        "def append_run_log(\n",
        "    log_path: str,\n",
        "    *,\n",
        "    params: dict,\n",
        "    seq_len: int,\n",
        "    input_size: int,\n",
        "    loss_train_per_epoch: list,\n",
        "    acc_train_per_epoch: list,\n",
        "    t_tot: float,\n",
        "    t_per_epoch: float,\n",
        "    acc_test: float,\n",
        "    acc_test_95CI_low: float,\n",
        "    acc_test_95CI_high: float,\n",
        "    t_inf: float,\n",
        "):\n",
        "    \"\"\"Append one row to CSV (create with header if missing).\"\"\"\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    row = {\n",
        "        \"timestamp\": ts,\n",
        "        \"params_json\": json.dumps(sanitize_params(params), ensure_ascii=False),\n",
        "        \"seq_len\": seq_len,\n",
        "        \"input_size\": input_size,\n",
        "        \"loss_train\": json.dumps([_to_scalar(x) for x in loss_train_per_epoch]),\n",
        "        \"acc_train\": json.dumps([_to_scalar(x) for x in acc_train_per_epoch]),\n",
        "        \"t_tot\": float(t_tot),\n",
        "        \"t_per_epoch\": float(t_per_epoch),\n",
        "        \"acc_test\": float(acc_test),\n",
        "        \"acc_test_95CI_low\":float(acc_test - 1.96*np.sqrt(acc_test*(1-acc_test))),\n",
        "        \"acc_test_95CI_high\":float(acc_test + 1.96*np.sqrt(acc_test*(1-acc_test))),\n",
        "        \"t_inf\": float(t_inf),\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame([row])\n",
        "    # Create with header if not exists; else append without header\n",
        "    if not os.path.exists(log_path):\n",
        "        df.to_csv(log_path, index=False)\n",
        "    else:\n",
        "        df.to_csv(log_path, index=False, mode=\"a\", header=False)\n",
        "\n",
        "    print(f\"Appended run to: {log_path}\")"
      ],
      "metadata": {
        "id": "WuBEb-CK0_r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load voltage-current mapping\n",
        "import pickle\n",
        "source_mapping = mapping_path\n",
        "with open(source_mapping, 'rb') as fp:\n",
        "    mapping = pickle.load(fp)\n",
        "\n",
        "# Device Simulator\n",
        "df = pd.read_excel(data_path).apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# EXP rows only (drop NaNs in EXP pair)\n",
        "exp = df[[\"vbg_exp\", \"ids_exp\"]].dropna(how=\"any\")\n",
        "b_vg_exp = exp[\"vbg_exp\"].to_numpy()\n",
        "b_id_exp = exp[\"ids_exp\"].to_numpy()\n",
        "\n",
        "# SIM rows only (drop NaNs in SIM pair)\n",
        "sim = df[[\"vbg_sim\", \"ids_sim\"]].dropna(how=\"any\")\n",
        "VBG_sim_new = sim[\"vbg_sim\"].to_numpy()\n",
        "ID_sim_new = sim[\"ids_sim\"].to_numpy()\n",
        "\n",
        "params = {\n",
        "    \"eps_ox1\": 3.45e-11, #F/m\n",
        "    \"eps_ox2\": 1.33e-10, #F/m\n",
        "    \"C_ox1\": 3.45e-3, #F/m\n",
        "    \"C_ox2\": 1.33e-2, #F/m\n",
        "    \"t_ox1\": 1e-8, #m\n",
        "    \"t_ox2\": 1e-8, #m\n",
        "    \"W\": 1.5e-5, #m\n",
        "    \"L\": 5e-7, #m\n",
        "    \"A\": 7.5e-12, #m^2\n",
        "    \"V_p\": 4, #V\n",
        "    \"V_ds\": 1e-2, #V\n",
        "     \"V_shift\": -1.5, #V\n",
        "    \"V_FB\": -0.95, #V\n",
        "    \"n_e\": 1.5, #a.u.\n",
        "    \"m\": 0.9, #a.u.\n",
        "    \"a1\": 0.72, #a.u., a2 = 1-a1\n",
        "    \"tau1\": 4, #s\n",
        "    \"tau2\": 506, #s\n",
        "    \"f\": 2.5e-2, #Hz\n",
        "    \"N_digits\": 8, #a.u.\n",
        "    \"VBG_sim_new\": VBG_sim_new,\n",
        "    \"ID_sim_new\": ID_sim_new,\n",
        "    \"VBG_exp\": b_vg_exp,\n",
        "    \"ID_exp\": b_id_exp,\n",
        "    \"gamma\": 0.2,\n",
        "    \"rho\": 1,\n",
        "    \"val_size\":5000, # Validation set\n",
        "    \"train_size\": 12000, # Smaller training set for fast training\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.0001,\n",
        "    \"scaling\": 1e7,\n",
        "    \"mapping\": mapping, # For original ICGS\n",
        "}\n",
        "\n",
        "import time\n",
        "num_epochs = params[\"num_epochs\"]\n",
        "batch_size = params[\"batch_size\"]\n",
        "lr = params[\"lr\"]\n",
        "seq_len = 8\n",
        "input_size = int(576/seq_len)\n",
        "\n",
        "class ICGSReservoirLayer(nn.Module):\n",
        "    def __init__(self, input_size:int, seq_len:int, **params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.input_size = input_size\n",
        "        self.seq_len = seq_len\n",
        "        self.f = self.params.get(\"f\")\n",
        "        self.t_RC = np.linspace(0, self.seq_len/self.f,self.seq_len)\n",
        "\n",
        "        mapping_tensor = torch.zeros((2**self.seq_len, self.seq_len))\n",
        "        for i in range(2**self.seq_len):\n",
        "            key = tuple(int(b) for b in format(i, f'0{self.seq_len}b'))\n",
        "            key = key + (0,) * max(0, 8 - self.seq_len)\n",
        "            value = mapping.get(tuple(key), [0.0] * self.seq_len)      # Fallback to zeros\n",
        "            value = value[:self.seq_len]\n",
        "            mapping_tensor[i] = torch.tensor(value)\n",
        "\n",
        "        self.register_buffer(\"mapping_tensor\", mapping_tensor)\n",
        "        self.register_buffer(\"bit_weights\", (2 ** torch.arange(self.seq_len - 1, -1, -1)))  # [128, 64, ..., 1]\n",
        "        #self.register_buffer(\"bit_weights\", (2 ** torch.arange(7, -1, -1)))  # [128, 64, ..., 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len = self.seq_len, input_size = self.input_size)\n",
        "        batch_size, self.seq_len, self.input_size = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        # Initial reservoir state\n",
        "        h_t = torch.zeros(batch_size, self.seq_len, self.input_size, device=device)\n",
        "\n",
        "        # shape: [batch_size * input_size, seq_len]\n",
        "        x = x.permute(0, 2, 1)  # [batch, input, seq_len]\n",
        "        #x = x.reshape(-1, self.seq_len).long()  # [batch * input, seq_len]\n",
        "        x = x.reshape(-1, self.seq_len)  # [batch * input, seq_len]\n",
        "        indices = torch.matmul(x, self.bit_weights.int().to(x.device))  # [batch * input]\n",
        "        responses = self.mapping_tensor[indices]\n",
        "        h_t = responses.reshape(batch_size, input_size, seq_len).permute(0, 2, 1)\n",
        "        return h_t*self.params.get(\"scaling\")  # Final reservoir state used for classification\n",
        "\n",
        "class ICGSReservoirNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, **params):\n",
        "        super().__init__()\n",
        "        self.reservoir = ICGSReservoirLayer(input_size, seq_len, **params)\n",
        "        # Normalization\n",
        "        self.bn = nn.BatchNorm1d(seq_len*input_size)\n",
        "        # test on nonlinear projection\n",
        "        self.readout = nn.Linear(seq_len*input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        reservoir_state = self.reservoir(x)\n",
        "        reservoir_state_reshaped = torch.reshape(reservoir_state, (reservoir_state.size(dim=0), reservoir_state.size(dim=1)* reservoir_state.size(dim=2)))\n",
        "        reservoir_state_norm = self.bn(reservoir_state_reshaped)\n",
        "        out = self.readout(reservoir_state_norm)\n",
        "        #out = self.readout(reservoir_state_reshaped)\n",
        "        return out"
      ],
      "metadata": {
        "id": "xO4an5Qz5sxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST (Binarized)"
      ],
      "metadata": {
        "id": "yh1LFhHgtGvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare MNIST Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def preprocess_image(tensor_img, threshold = 20):\n",
        "    # tensor_img shape: [1, 28, 28], values in [0.0, 1.0]\n",
        "    tensor_img = tensor_img.squeeze(0)*255\n",
        "    binary_img = (tensor_img > threshold).int() # binarization\n",
        "    cropped = binary_img[2:-2,2:-2] # crop the image to size [24,24]\n",
        "    reshaped = cropped.reshape(seq_len,int(576/seq_len)) # seq_len = 8, input_size = 24*24/8 = 72\n",
        "    return reshaped\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: preprocess_image(x))  # shape: [8, 72]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Validation dataset\n",
        "from torch.utils.data import random_split\n",
        "train_size = len(train_dataset) - params[\"val_size\"]\n",
        "train_subset, val_subset = random_split(\n",
        "    train_dataset, [train_size,  params[\"val_size\"]],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "idx_small = torch.randperm(len(train_subset), generator=torch.Generator().manual_seed(42))[:params[\"train_size\"]]\n",
        "train_subset_small = Subset(train_subset, idx_small)\n",
        "train_loader_local = DataLoader(train_subset_small, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader         = DataLoader(val_subset,   batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "008EzNkv9s5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac323836-423f-4cba-ae7c-2fc2ba6af84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.71MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.78MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ICG_model = ICGSReservoirNet(input_size = input_size, seq_len = seq_len, output_size=10, **params).to(device)\n",
        "optimizer = torch.optim.Adam(ICG_model.readout.parameters(), lr=lr)  # Only train readout\n",
        "\n",
        "loss_train_hist = []\n",
        "acc_train_hist = []\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    ICG_model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = ICG_model(x)\n",
        "        output = F.log_softmax(output,dim =1)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    loss_train_hist.append(total_loss)\n",
        "    acc_train_hist.append(acc)\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "end_time = time.time()\n",
        "t_total = end_time - start_time\n",
        "t_per_epoch = t_total / num_epochs\n",
        "\n",
        "print(f\"Total training time: {t_total:.2f} seconds\")\n",
        "print(f\"Training time per epoch: {t_per_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4XoImzDFtE",
        "outputId": "f7b99356-228c-4170-d906-5fd455285925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 845.8691 | Accuracy: 75.73%\n",
            "Epoch 2 | Loss: 420.0674 | Accuracy: 88.12%\n",
            "Epoch 3 | Loss: 351.6660 | Accuracy: 89.55%\n",
            "Epoch 4 | Loss: 319.3690 | Accuracy: 90.45%\n",
            "Epoch 5 | Loss: 301.3777 | Accuracy: 90.96%\n",
            "Epoch 6 | Loss: 288.2765 | Accuracy: 91.23%\n",
            "Epoch 7 | Loss: 281.1116 | Accuracy: 91.37%\n",
            "Epoch 8 | Loss: 274.8292 | Accuracy: 91.62%\n",
            "Epoch 9 | Loss: 269.2461 | Accuracy: 91.89%\n",
            "Epoch 10 | Loss: 266.2864 | Accuracy: 91.86%\n",
            "Epoch 11 | Loss: 260.3113 | Accuracy: 92.06%\n",
            "Epoch 12 | Loss: 259.1507 | Accuracy: 92.13%\n",
            "Epoch 13 | Loss: 256.0999 | Accuracy: 92.20%\n",
            "Epoch 14 | Loss: 252.2376 | Accuracy: 92.36%\n",
            "Epoch 15 | Loss: 252.8889 | Accuracy: 92.35%\n",
            "Epoch 16 | Loss: 250.1048 | Accuracy: 92.34%\n",
            "Epoch 17 | Loss: 248.9287 | Accuracy: 92.44%\n",
            "Epoch 18 | Loss: 247.3616 | Accuracy: 92.37%\n",
            "Epoch 19 | Loss: 244.8729 | Accuracy: 92.52%\n",
            "Epoch 20 | Loss: 243.1103 | Accuracy: 92.56%\n",
            "Epoch 21 | Loss: 242.2095 | Accuracy: 92.55%\n",
            "Epoch 22 | Loss: 242.5478 | Accuracy: 92.62%\n",
            "Epoch 23 | Loss: 241.5591 | Accuracy: 92.60%\n",
            "Epoch 24 | Loss: 239.5967 | Accuracy: 92.68%\n",
            "Epoch 25 | Loss: 239.7154 | Accuracy: 92.64%\n",
            "Epoch 26 | Loss: 236.5142 | Accuracy: 92.78%\n",
            "Epoch 27 | Loss: 237.1064 | Accuracy: 92.80%\n",
            "Epoch 28 | Loss: 236.3919 | Accuracy: 92.77%\n",
            "Epoch 29 | Loss: 236.0250 | Accuracy: 92.80%\n",
            "Epoch 30 | Loss: 234.4533 | Accuracy: 92.84%\n",
            "Total training time: 585.90 seconds\n",
            "Training time per epoch: 19.53 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "ICG_model.eval()  # set model to evaluation mode\n",
        "tic = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = ICG_model(x)\n",
        "        preds = output.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "# Inference time\n",
        "t_inf = time.time()-tic\n",
        "\n",
        "# Accuracy\n",
        "acc_test = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {acc_test * 100:.2f}% | Inference time: {t_inf:.2f} seconds\")\n",
        "\n",
        "# Accuracy (95% Confidence Interval)\n",
        "SE_test = np.sqrt(acc_test * (1 - acc_test) / len(all_labels))\n",
        "z_score = 1.96  # 95% confidence interval\n",
        "CI_test = (acc_test - z_score * SE_test, acc_test + z_score * SE_test)\n",
        "print(f\"Test Accuracy (95% CI): {CI_test[0]*100:.2f}% - {CI_test[1]*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "append_run_log(\n",
        "    LOG_PATH,\n",
        "    params=params,\n",
        "    seq_len=seq_len,\n",
        "    input_size=input_size,\n",
        "    loss_train_per_epoch=loss_train_hist,\n",
        "    acc_train_per_epoch=acc_train_hist,\n",
        "    t_tot=t_total,\n",
        "    t_per_epoch=t_per_epoch,\n",
        "    acc_test=acc_test,\n",
        "    acc_test_95CI_low=CI_test[0],\n",
        "    acc_test_95CI_high=CI_test[1],\n",
        "    t_inf=t_inf,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "l2nsjYow1H5I",
        "outputId": "8a598070-4007-4c5f-e265-f895a90ce9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 92.85% | Inference time: 8.02 seconds\n",
            "Test Accuracy (95% CI): 92.34% - 93.36%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appended run to: /content/drive/MyDrive/oicgs_logs/ICGS_update_log.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "9Wngqg07Zyci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oICGS(signal,**params):\n",
        "\n",
        "    def interfacial_charge(Vp, **params):\n",
        "        try:\n",
        "          m      = params[\"m\"]\n",
        "          t_ox1  = params[\"t_ox1\"]\n",
        "          t_ox2  = params[\"t_ox2\"]\n",
        "          eps_ox1= params[\"eps_ox1\"]\n",
        "          eps_ox2= params[\"eps_ox2\"]\n",
        "          A      = params[\"A\"]\n",
        "        except KeyError as e:\n",
        "          raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "        E_ox1 = Vp / (t_ox1 + m * t_ox2)\n",
        "        E_ox2 = m * Vp / (t_ox1 + m * t_ox2)\n",
        "        sigma = - eps_ox1 * E_ox1 + eps_ox2 * E_ox2\n",
        "        return [E_ox1, E_ox2, sigma]\n",
        "\n",
        "    def decay_func(t,**params):\n",
        "      try:\n",
        "        a1 = params[\"a1\"]\n",
        "        a2 = 1-a1\n",
        "        tau1 = params[\"tau1\"]\n",
        "        tau2 = params[\"tau2\"]\n",
        "      except KeyError as e:\n",
        "        raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "      return a1*np.exp(-t/tau1)+a2*np.exp(-t/tau2)\n",
        "\n",
        "    def threshold_shift(sigma, Vshift, **params):\n",
        "      try:\n",
        "        t_ox = params[\"t_ox1\"]\n",
        "        eps_ox = params[\"eps_ox1\"]\n",
        "      except KeyError as e:\n",
        "        raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "      return -sigma * t_ox/eps_ox + Vshift\n",
        "\n",
        "    def find_index(x,array):\n",
        "        diff_array = np.absolute(np.asarray(array)-x)\n",
        "        index = diff_array.argmin()\n",
        "        return index\n",
        "\n",
        "\n",
        "    f = params[\"f\"]\n",
        "    time = np.linspace(0,len(signal)/f,len(signal))\n",
        "    VBG = params[\"VBG_sim_new\"]\n",
        "    ID = params[\"ID_sim_new\"]\n",
        "    gamma = params[\"gamma\"]\n",
        "\n",
        "    #Initialization\n",
        "    if len(time)>1:\n",
        "        t_interval = time[1]-time[0]\n",
        "    else:\n",
        "        t_interval = 0\n",
        "    sigma_initial = interfacial_charge(Vp = 0, **params)[2]\n",
        "    sigma_accumulated = [sigma_initial]\n",
        "    sigma_accumulated_afterdecay = [0]\n",
        "    sigma_generated = []\n",
        "    delta_vth_sigma = []\n",
        "    delta_vth_total = []\n",
        "    sigma_saturate = []\n",
        "    sigma_generated_temp = []\n",
        "    current_index = []\n",
        "    current = []\n",
        "\n",
        "    #Set threshold\n",
        "    signal_max, signal_min = max(signal), min(signal)\n",
        "    sigma_saturate_max, sigma_saturate_min = interfacial_charge(Vp = signal_max, **params)[2], interfacial_charge(Vp = signal_min, **params)[2]\n",
        "\n",
        "    if sigma_saturate_max>0 and sigma_saturate_min>0:\n",
        "        sigma_saturate_pos = max(sigma_saturate_max, sigma_saturate_min)\n",
        "        sigma_saturate_neg = 0\n",
        "    elif sigma_saturate_max >0 and sigma_saturate_min <=0:\n",
        "        sigma_saturate_pos = sigma_saturate_max\n",
        "        sigma_saturate_neg = sigma_saturate_min\n",
        "    elif sigma_saturate_max <=0 and sigma_saturate_min >0:\n",
        "        sigma_saturate_pos = sigma_saturate_min\n",
        "        sigma_saturate_neg = sigma_saturate_max\n",
        "    else:\n",
        "        sigma_saturate_pos = 0\n",
        "        sigma_saturate_neg = min(sigma_saturate_max, sigma_saturate_min)\n",
        "\n",
        "    # Calculate charge\n",
        "    for i in range(len(time)):\n",
        "        delta_vth_total.append(float(signal[i]))\n",
        "        sigma_saturate.append(interfacial_charge(Vp = signal[i], **params)[2])\n",
        "        sigma_generated_temp.append(sigma_saturate[i]*gamma*t_interval)\n",
        "\n",
        "        if sigma_accumulated_afterdecay[i]+sigma_generated_temp[i] > sigma_saturate_pos:\n",
        "            sigma_generated.append(sigma_saturate_pos-sigma_accumulated_afterdecay[i])\n",
        "            sigma_accumulated.append(sigma_saturate_pos)\n",
        "\n",
        "        elif sigma_accumulated_afterdecay[i]+sigma_generated_temp[i] < sigma_saturate_neg:\n",
        "            sigma_generated.append(sigma_saturate_neg-sigma_accumulated_afterdecay[i])\n",
        "            sigma_accumulated.append(sigma_saturate_neg)\n",
        "\n",
        "        else:\n",
        "            sigma_generated.append(sigma_generated_temp[i])\n",
        "            sigma_accumulated.append(sigma_accumulated_afterdecay[i]+sigma_generated[i])\n",
        "\n",
        "        sigma_accumulated_afterdecay_temp = 0\n",
        "        for j in range(len(sigma_generated)):\n",
        "            sigma_accumulated_afterdecay_temp += sigma_generated[j]*decay_func(time[i]-time[j], **params)\n",
        "        sigma_accumulated_afterdecay.append(sigma_accumulated_afterdecay_temp)\n",
        "\n",
        "        # Calculate threshold voltage shift and current\n",
        "        delta_vth_sigma.append(threshold_shift(sigma_accumulated[i],Vshift = params[\"V_shift\"],**params))\n",
        "        delta_vth_total[i] += threshold_shift(sigma_accumulated[i],Vshift = params[\"V_shift\"],**params)\n",
        "        current_index.append(find_index(delta_vth_total[i],VBG))\n",
        "        current.append(ID[find_index(delta_vth_total[i],VBG)])\n",
        "\n",
        "    return [sigma_generated,sigma_accumulated,delta_vth_sigma,delta_vth_total,current]\n",
        "\n",
        "class ICGSReservoirLayer(nn.Module):\n",
        "    def __init__(self, input_size:int, seq_len:int, **params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.input_size = input_size\n",
        "        self.seq_len = seq_len\n",
        "        self.f = self.params.get(\"f\")\n",
        "        self.t_RC = np.linspace(0, self.seq_len/self.f,self.seq_len)\n",
        "\n",
        "        mapping_tensor = torch.zeros((2**self.seq_len, self.seq_len))\n",
        "        for i in range(2**self.seq_len):\n",
        "            key = tuple(int(b) for b in format(i, f'0{self.seq_len}b'))\n",
        "            key = key + (0,) * max(0, 8 - self.seq_len)\n",
        "            value = mapping.get(tuple(key), [0.0] * self.seq_len)      # Fallback to zeros\n",
        "            value = value[:self.seq_len]\n",
        "            mapping_tensor[i] = torch.tensor(value)\n",
        "\n",
        "        self.register_buffer(\"mapping_tensor\", mapping_tensor)\n",
        "        self.register_buffer(\"bit_weights\", (2 ** torch.arange(self.seq_len - 1, -1, -1)))  # [128, 64, ..., 1]\n",
        "        #self.register_buffer(\"bit_weights\", (2 ** torch.arange(7, -1, -1)))  # [128, 64, ..., 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len = self.seq_len, input_size = self.input_size)\n",
        "        batch_size, self.seq_len, self.input_size = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        # Initial reservoir state\n",
        "        h_t = torch.zeros(batch_size, self.seq_len, self.input_size, device=device)\n",
        "\n",
        "        # shape: [batch_size * input_size, seq_len]\n",
        "        x = x.permute(0, 2, 1)  # [batch, input, seq_len]\n",
        "        x = x.reshape(-1, self.seq_len).long()  # [batch * input, seq_len]\n",
        "        #x = x.reshape(-1, self.seq_len)  # [batch * input, seq_len]\n",
        "        indices = torch.matmul(x, self.bit_weights.to(x.device))  # [batch * input]\n",
        "        responses = self.mapping_tensor[indices]\n",
        "        h_t = responses.reshape(batch_size, input_size, seq_len).permute(0, 2, 1)\n",
        "        return h_t*self.params.get(\"scaling\")  # Final reservoir state used for classification\n",
        "\n",
        "class ICGSReservoirNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, **params):\n",
        "        super().__init__()\n",
        "        self.reservoir = ICGSReservoirLayer(input_size, seq_len, **params)\n",
        "        # Normalization\n",
        "        self.bn = nn.BatchNorm1d(seq_len*input_size)\n",
        "        # test on nonlinear projection\n",
        "        self.readout = nn.Linear(seq_len*input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        reservoir_state = self.reservoir(x)\n",
        "        reservoir_state_reshaped = torch.reshape(reservoir_state, (reservoir_state.size(dim=0), reservoir_state.size(dim=1)* reservoir_state.size(dim=2)))\n",
        "        reservoir_state_norm = self.bn(reservoir_state_reshaped)\n",
        "        out = self.readout(reservoir_state_norm)\n",
        "        #out = self.readout(reservoir_state_reshaped)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LO39CRff901p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare MNIST Dataset\n",
        "train_size = 12000\n",
        "val_size = 5000\n",
        "\n",
        "\n",
        "def preprocess_image(tensor_img, threshold = 20):\n",
        "    # tensor_img shape: [1, 28, 28], values in [0.0, 1.0]\n",
        "    tensor_img = tensor_img.squeeze(0)*255\n",
        "    binary_img = (tensor_img > threshold).int() # binarization\n",
        "    cropped = binary_img[2:-2,2:-2] # crop the image to size [24,24]\n",
        "    reshaped = cropped.reshape(seq_len,int(576/seq_len)) # seq_len = 8, input_size = 24*24/8 = 72\n",
        "    return reshaped\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: preprocess_image(x))  # shape: [8, 72]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Validation dataset\n",
        "from torch.utils.data import random_split\n",
        "train_size = len(train_dataset) - val_size\n",
        "train_subset, val_subset = random_split(\n",
        "    train_dataset, [train_size,  val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "idx_small = torch.randperm(len(train_subset), generator=torch.Generator().manual_seed(42))[:train_size]\n",
        "train_subset_small = Subset(train_subset, idx_small)\n",
        "train_loader_local = DataLoader(train_subset_small, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader         = DataLoader(val_subset,   batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "FBTZaehsALGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_trials = 10\n",
        "\n",
        "def generate_binary_input(N, scaling = -3):\n",
        "    input_string = []\n",
        "    input_list = []\n",
        "    input_list_with_zeros = []\n",
        "    for i in range (pow(2,N)):\n",
        "      binary_string = bin(i).replace(\"0b\",'').zfill(N)\n",
        "      input_string.append(binary_string)\n",
        "      binary_list = [int(bit)*scaling for bit in binary_string]\n",
        "      binary_list_with_zeros = [0]\n",
        "      for bit in binary_list:\n",
        "          binary_list_with_zeros.append(bit)\n",
        "          binary_list_with_zeros.append(0)  # Add 0 after each digit\n",
        "      input_list.append(binary_list)\n",
        "      input_list_with_zeros.append(binary_list_with_zeros)\n",
        "    return input_string, input_list, input_list_with_zeros\n",
        "\n",
        "# ---- Per-trial CSV logging (create once) ----\n",
        "#TRIAL_LOG_DIR = \"/content/drive/MyDrive/icgs_trial_logs\" # Log in Drive\n",
        "TRIAL_LOG_DIR = \"./trial_logs\" # Log in Colab\n",
        "os.makedirs(TRIAL_LOG_DIR, exist_ok=True)\n",
        "TRIAL_LOG_CSV = os.path.join(TRIAL_LOG_DIR, \"oICGS_log.csv\")\n",
        "\n",
        "def _ensure_trial_log_header():\n",
        "    if not os.path.exists(TRIAL_LOG_CSV):\n",
        "        with open(TRIAL_LOG_CSV, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                \"timestamp\", \"trial_number\", \"state\",\n",
        "                \"train_size\", \"val_size\", \"test_size\",\n",
        "                \"num_epochs_run\", \"batch_size\", \"learning_rate\", \"output_scaling\",\n",
        "                \"objective_best_val_acc\", \"test_acc\",\n",
        "                \"params_json\"\n",
        "            ])\n",
        "            f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "def _append_trial_log_row(row):\n",
        "    with open(TRIAL_LOG_CSV, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(row)\n",
        "        f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "_ensure_trial_log_header()\n",
        "\n",
        "# Define the multi-objective function\n",
        "def objective(trial):\n",
        "\n",
        "    params = {\n",
        "    \"eps_ox1\": 3.45e-11, #F/m\n",
        "    \"eps_ox2\": 1.33e-10, #F/m\n",
        "    \"C_ox1\": 3.45e-3, #F/m\n",
        "    \"C_ox2\": 1.33e-2, #F/m\n",
        "    \"t_ox1\": 1e-8, #m\n",
        "    \"t_ox2\": 1e-8, #m\n",
        "    \"W\": 1.5e-5, #m\n",
        "    \"L\": 5e-7, #m\n",
        "    \"A\": 7.5e-12, #m^2\n",
        "    \"V_p\": 1.133, #input_scaling (V)\n",
        "    \"V_ds\": 1e-2, #V\n",
        "    \"V_shift\": 0, #V\n",
        "    \"V_FB\": -0.95, #V\n",
        "    \"n_e\": 1.5, #a.u.\n",
        "    \"m\": trial.suggest_float(\"m\",1e-1,10,log=True), #a.u.\n",
        "    \"a1\": trial.suggest_float(\"a1\", 0, 1), #a.u., a2 = 1-a1\n",
        "    \"tau1\": trial.suggest_int(\"tau1\", 1, 100, log=True), #s\n",
        "    \"tau2\": trial.suggest_int(\"tau2\", 1e2, 1e3, log=True), #s\n",
        "    \"f\": trial.suggest_float(\"f\", 1e-2, 1e2, log=True), #Hz\n",
        "    \"N_digits\": 8, #a.u.\n",
        "    \"VBG_sim_new\": VBG_sim_new,\n",
        "    \"ID_sim_new\": ID_sim_new,\n",
        "    \"VBG_exp\": b_vg_exp,\n",
        "    \"ID_exp\": b_id_exp,\n",
        "    \"gamma\": trial.suggest_float(\"gamma\", 1e-4,1e-1, log=True),\n",
        "    \"rho\": 1,\n",
        "    \"val_size\":5000, # Validation set\n",
        "    \"train_size\": 12000, # Smaller training set for fast training\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.0001,\n",
        "    \"scaling\": 1e7,\n",
        "    \"mapping\": mapping, # For original ICGS\n",
        "    }\n",
        "    seq_len = 8\n",
        "\n",
        "    input_size = int(576/seq_len)\n",
        "    f = params[\"f\"]\n",
        "    all_input_string,_,all_input = generate_binary_input(seq_len,params[\"V_p\"])\n",
        "    true_seq_len = len(all_input[0])\n",
        "    t_input = linspace(0, 1/f*true_seq_len,true_seq_len)\n",
        "    current_output = []\n",
        "\n",
        "    for i in range(len(all_input)):\n",
        "      input_test = all_input[i]\n",
        "      [_, _, _, _, current_mapping] = oICGS(signal = input_test,**params)\n",
        "      current_mapping_read = current_mapping[1::2]\n",
        "      current_output.append(current_mapping_read)\n",
        "      #plt.plot(current_mapping_read,label=input_test[1::2])\n",
        "\n",
        "    len_row = len(all_input_string)\n",
        "    len_col = len(current_output[1])\n",
        "    current_df = pd.DataFrame(current_output)\n",
        "    df = pd.DataFrame()\n",
        "    df['input'] = all_input_string\n",
        "    for i in range (len_col):\n",
        "      df[f'current_{i+1}'] = current_df[i]\n",
        "    keys = [tuple(int(digit) for digit in str(value).zfill(seq_len)) for value in df.iloc[:, 0]]\n",
        "    values = df.iloc[:, 1:].values.tolist()\n",
        "    source_mapping = dict(zip(keys, values))\n",
        "\n",
        "    # Training\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    num_epochs = params[\"num_epochs\"]\n",
        "    batch_size = params[\"batch_size\"]\n",
        "    lr = params[\"lr\"]\n",
        "    output_scaling = params[\"scaling\"]\n",
        "    max_train = params[\"train_size\"]\n",
        "    val_size = params[\"val_size\"]\n",
        "    best_val_acc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    patience = 3\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pin = (device.type == \"cuda\")\n",
        "\n",
        "    # Tracking for logging\n",
        "    epochs_run = 0\n",
        "    last_val_acc = float(\"nan\")\n",
        "\n",
        "    ICG_model = ICGSReservoirNet(input_size = input_size,\n",
        "                                 seq_len = seq_len,\n",
        "                                 output_size = 10,\n",
        "                                 **params).to(device)\n",
        "\n",
        "    # Precompute reservoir states (once per trial instead of once per epoch)\n",
        "    ICG_model.eval()\n",
        "    train_feats, train_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in train_loader_local:\n",
        "            xb = xb.to(device).long()\n",
        "            h = ICG_model.reservoir(xb).reshape(xb.size(0), -1)  # [B, 8*72]\n",
        "            h_norm = ICG_model.bn(h)\n",
        "            train_feats.append(h_norm)\n",
        "            train_targets.append(yb.to(device))\n",
        "    train_X = torch.cat(train_feats, dim=0)\n",
        "    train_y = torch.cat(train_targets, dim=0)\n",
        "\n",
        "    val_feats, val_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device).long()\n",
        "            h = ICG_model.reservoir(xb).reshape(xb.size(0), -1)\n",
        "            val_feats.append(h)\n",
        "            val_targets.append(yb.to(device))\n",
        "    val_X = torch.cat(val_feats, dim=0)\n",
        "    val_y = torch.cat(val_targets, dim=0)\n",
        "\n",
        "    # Feature loaders (same batch size as before)\n",
        "    feat_train_loader = DataLoader(\n",
        "        torch.utils.data.TensorDataset(train_X, train_y),\n",
        "        batch_size=64, shuffle=True, num_workers=2, pin_memory=pin\n",
        "    )\n",
        "    feat_val_loader = DataLoader(\n",
        "        torch.utils.data.TensorDataset(val_X, val_y),\n",
        "        batch_size=64, shuffle=False, num_workers=2, pin_memory=pin\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(ICG_model.readout.parameters(), lr=lr)  # Only train readout\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    try:\n",
        "      for epoch in range(num_epochs):\n",
        "          ICG_model.train()\n",
        "          total_loss = 0\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          for h, y in feat_train_loader:\n",
        "              h, y = h.to(device), y.to(device)\n",
        "              optimizer.zero_grad()\n",
        "              output = ICG_model.readout(h)\n",
        "              output = F.log_softmax(output,dim =1)\n",
        "              loss = criterion(output, y)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              total_loss += loss.item()\n",
        "              pred = output.argmax(dim=1)\n",
        "              correct += (pred == y).sum().item()\n",
        "              total += y.size(0)\n",
        "\n",
        "          acc = 100 * correct / total\n",
        "          #print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
        "\n",
        "          # --- per-epoch validation ---\n",
        "          ICG_model.eval()\n",
        "          val_correct = 0\n",
        "          val_total = 0\n",
        "          with torch.no_grad():\n",
        "              for h_val, y_val in feat_val_loader:\n",
        "                  h_val, y_val = h_val.to(device), y_val.to(device)\n",
        "                  logits_val = F.log_softmax(ICG_model.readout(h_val),dim=1)\n",
        "                  pred_val = logits_val.argmax(dim=1)\n",
        "                  val_correct += (pred_val == y_val).sum().item()\n",
        "                  val_total  += y_val.size(0)\n",
        "          val_acc = 100 * val_correct / val_total\n",
        "\n",
        "          # report & prune on validation accuracy\n",
        "          trial.report(val_acc / 100.0, step=epoch)\n",
        "          if trial.should_prune():\n",
        "              raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "          # early stopping on validation plateau\n",
        "          if val_acc > best_val_acc + 1e-4:\n",
        "              best_val_acc = val_acc\n",
        "              epochs_no_improve = 0\n",
        "          else:\n",
        "              epochs_no_improve += 1\n",
        "              if epochs_no_improve >= patience:\n",
        "                  break\n",
        "\n",
        "          # end of epoch\n",
        "          epochs_run = epoch + 1\n",
        "          last_val_acc = val_acc\n",
        "\n",
        "      # ---- test evaluation (compute once per trial) ----\n",
        "      test_feats, test_targets = [], []\n",
        "      with torch.no_grad():\n",
        "          for xb, yb in test_loader:\n",
        "              xb = xb.to(device).long()\n",
        "              h = ICG_model.reservoir(xb).reshape(xb.size(0), -1)\n",
        "              test_feats.append(h)\n",
        "              test_targets.append(yb.to(device))\n",
        "      test_X = torch.cat(test_feats, dim=0)\n",
        "      test_y = torch.cat(test_targets, dim=0)\n",
        "\n",
        "      ICG_model.eval()\n",
        "      with torch.no_grad():\n",
        "          logits = F.log_softmax(ICG_model.readout(test_X),dim=1)\n",
        "          preds  = logits.argmax(1)\n",
        "          test_acc = (preds == test_y).float().mean().item()  # 0..1\n",
        "\n",
        "      # ---- append CSV row for COMPLETED trial ----\n",
        "      _append_trial_log_row([\n",
        "          time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "          trial.number, \"COMPLETE\",\n",
        "          len(train_subset_small), val_size, len(test_dataset),\n",
        "          epochs_run, batch_size, lr, output_scaling,\n",
        "          f\"{best_val_acc/100.0:.6f}\", f\"{test_acc:.6f}\",\n",
        "          json.dumps(trial.params)\n",
        "      ])\n",
        "\n",
        "    except optuna.exceptions.TrialPruned:\n",
        "        # Log PRUNED trial (no test accuracy)\n",
        "        _append_trial_log_row([\n",
        "            time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            trial.number, \"PRUNED\",\n",
        "            len(train_subset_small), val_size, len(test_dataset),\n",
        "            epochs_run, batch_size, lr, output_scaling,\n",
        "            f\"{(last_val_acc/100.0) if last_val_acc==last_val_acc else ''}\",\n",
        "            \"\",  # no test acc for pruned trials\n",
        "            json.dumps(trial.params)\n",
        "        ])\n",
        "        raise  # re-raise so Optuna marks it pruned\n",
        "\n",
        "    except Exception as e:\n",
        "      # Optional: log FAILED trials too\n",
        "      _append_trial_log_row([\n",
        "          time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "          trial.number, \"FAILED\",\n",
        "          len(train_subset_small), val_size, len(test_dataset),\n",
        "          epochs_run, batch_size, lr, output_scaling,\n",
        "          f\"{(last_val_acc/100.0) if last_val_acc==last_val_acc else ''}\",\n",
        "          \"\",\n",
        "          json.dumps({**trial.params, \"_error\": str(e)})\n",
        "      ])\n",
        "      raise\n",
        "\n",
        "    # Return: maximize test accuracy\n",
        "    return best_val_acc / 100.0\n",
        "\n",
        "\n",
        "# Run multi-objective optimization\n",
        "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True,\n",
        "                                     group=True, n_startup_trials=10,\n",
        "                                     n_ei_candidates=64)\n",
        "\n",
        "#OPTUNA_DIR = \"/content/drive/MyDrive/optuna_new\" # Log in Drive\n",
        "OPTUNA_DIR = \"./optuna_new\" # Log in Colab\n",
        "os.makedirs(OPTUNA_DIR, exist_ok=True)\n",
        "STORAGE_URL = f\"sqlite:///{OPTUNA_DIR}/icgs_mnist.sqlite3\"\n",
        "STUDY_NAME  = \"oicgs_mnist\"\n",
        "\n",
        "pruner = optuna.pruners.PatientPruner(\n",
        "    optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2, interval_steps=2),\n",
        "    patience=1  # need at least one consecutive prune signal\n",
        ")\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    sampler=sampler,\n",
        "    pruner=pruner,\n",
        "    storage=STORAGE_URL,\n",
        "    study_name=STUDY_NAME,\n",
        "    load_if_exists=True\n",
        ")\n",
        "study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "# --- Intensification: enqueue a few jittered neighbors around the current best ---\n",
        "best = study.best_trial\n",
        "bp = best.params\n",
        "\n",
        "def _clip(v, lo, hi):\n",
        "    return float(np.clip(v, lo, hi))\n",
        "\n",
        "# multiplicative jitters for log-scale params; additive for bounded linear ones\n",
        "scales = [0.625, 1.6]  # ≈ /1.6 and ×1.6\n",
        "neighbors = []\n",
        "\n",
        "for s in scales:\n",
        "    neighbors.append({\n",
        "        \"f\":       _clip(bp[\"f\"] * s,           1e-2, 1e2),\n",
        "        \"gamma\":   _clip(bp[\"gamma\"] * s,       1e-4, 1e-1),\n",
        "        \"a1\":      _clip(bp[\"a1\"] + (0.1 if s>1 else -0.1), 0.0, 1.0),\n",
        "        \"tau1\":    int(np.clip(round(bp[\"tau1\"] * s),        1,    100)),\n",
        "        \"tau2\":    int(np.clip(round(bp[\"tau2\"] * s),        100,  1000)),\n",
        "        \"m\":       _clip(bp[\"m\"] * s,           1e-1, 10.0),\n",
        "    })\n",
        "\n",
        "for params in neighbors:\n",
        "    study.enqueue_trial(params)\n",
        "\n",
        "# run a short polish phase (e.g., 6–8 trials)\n",
        "study.optimize(objective, n_trials=6)\n",
        "\n",
        "# Show best solution\n",
        "best = study.best_trial\n",
        "print(f\"\\nBest trial #{best.number}\")\n",
        "print(f\"Test accuracy: {best.value:.4f}\")\n",
        "print(f\"Params: {best.params}\")\n",
        "\n",
        "# === FINAL TRAINING ON FULL DATA + ROBUST LOGGING ===\n",
        "import os, json, time, csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset, Subset\n",
        "\n",
        "# ---- 1) Paths & run metadata ----\n",
        "RUN_STAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "run_name   = f\"mnist_icgs_final_{RUN_STAMP}\"\n",
        "log_csv    = os.path.join(LOG_DIR, f\"{run_name}.csv\")\n",
        "cfg_json   = os.path.join(LOG_DIR, f\"{run_name}_config.json\")\n",
        "ckpt_path  = os.path.join(LOG_DIR, f\"{run_name}_best.pt\")\n",
        "cm_csv     = os.path.join(LOG_DIR, f\"{run_name}_confusion_matrix.csv\")\n",
        "\n",
        "# ---- 2) Pull best params from Optuna (after your study.optimize + polish) ----\n",
        "best = study.best_trial\n",
        "bp   = best.params  # keys: scaling, f, gamma, rho, a1, tau1, tau2, m (per your search space)\n",
        "\n",
        "# fixed settings consistent with your code\n",
        "seq_len         = 8\n",
        "output_scaling  = 1e7        # scale reservoir outputs once here (currents)\n",
        "val_size        = 5000        # small val split for early stopping\n",
        "batch_size      = 64\n",
        "num_workers     = 2\n",
        "max_epochs      = 30\n",
        "patience        = 5\n",
        "lr              = 1e-4\n",
        "\n",
        "# ---- 3) Helper: build mapping with the best params ----\n",
        "def build_mapping_from_params(seq_len, input_scaling, **params):\n",
        "    input_string, _, all_input = generate_binary_input(seq_len, input_scaling)\n",
        "    true_T = len(all_input[0])                 # 2*seq_len+1\n",
        "    t_input = np.linspace(0, (1.0/params[\"f\"])*true_T, true_T)\n",
        "    current_output = []\n",
        "    for inp in all_input:\n",
        "        *_, current_mapping = oICGS(signal=inp,**params)\n",
        "        current_output.append(current_mapping[1::2])   # exactly 8 samples\n",
        "    # pack mapping\n",
        "    keys = [tuple(int(d) for d in s.zfill(seq_len)) for s in input_string]\n",
        "    mapping = dict(zip(keys, np.asarray(current_output).tolist()))\n",
        "    return mapping\n",
        "\n",
        "# ---- 4) Instantiate model with best mapping ----\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin = (device.type == \"cuda\")\n",
        "\n",
        "mapping_best = build_mapping_from_params(\n",
        "    seq_len=seq_len,\n",
        "    input_scaling=1.133,\n",
        "    f=bp[\"f\"], gamma=bp[\"gamma\"], a1=bp[\"a1\"],\n",
        "    tau1=int(bp[\"tau1\"]), tau2=int(bp[\"tau2\"]), m=bp[\"m\"]\n",
        ")\n",
        "\n",
        "model = ICGSReservoirNet(input_size=72, seq_len=seq_len, output_size=10,\n",
        "                         mapping=mapping_best, scaling=output_scaling).to(device)\n",
        "readout = model.readout  # only this is trained\n",
        "optimizer = torch.optim.Adam(readout.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# ---- 5) Build full-data loaders (with a small held-out val split) ----\n",
        "train_size = len(train_dataset) - val_size\n",
        "train_subset, val_subset = random_split(\n",
        "    train_dataset, [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_loader_full = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "val_loader        = DataLoader(val_subset,   batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "test_loader_final = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "# ---- 6) Precompute reservoir features once (train/val/test) ----\n",
        "@torch.no_grad()\n",
        "def compute_features(dloader):\n",
        "    model.eval()\n",
        "    feats, targets = [], []\n",
        "    for xb, yb in dloader:\n",
        "        xb = xb.to(device).long()\n",
        "        h  = model.reservoir(xb).reshape(xb.size(0), -1)  # [B, 576]\n",
        "        h_norm = model.bn(h)\n",
        "        feats.append(h_norm)\n",
        "        targets.append(yb.to(device))\n",
        "    return torch.cat(feats, 0), torch.cat(targets, 0)\n",
        "\n",
        "train_X, train_y = compute_features(train_loader_full)\n",
        "val_X,   val_y   = compute_features(val_loader)\n",
        "test_X,  test_y  = compute_features(test_loader_final)\n",
        "\n",
        "feat_train_loader = DataLoader(TensorDataset(train_X, train_y),\n",
        "                               batch_size=batch_size, shuffle=True,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "feat_val_loader   = DataLoader(TensorDataset(val_X, val_y),\n",
        "                               batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "feat_test_loader  = DataLoader(TensorDataset(test_X, test_y),\n",
        "                               batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "# ---- 7) Prepare logging (CSV) + config JSON ----\n",
        "cfg = dict(\n",
        "    run_name=run_name,\n",
        "    timestamp=RUN_STAMP,\n",
        "    params=bp,\n",
        "    seq_len=seq_len,\n",
        "    output_scaling=output_scaling,\n",
        "    val_size=val_size,\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=max_epochs,\n",
        "    patience=patience,\n",
        "    lr=lr,\n",
        "    train_size=len(train_subset),\n",
        "    val_size_actual=len(val_subset),\n",
        "    test_size=len(test_dataset),\n",
        "    log_csv=log_csv,\n",
        "    ckpt_path=ckpt_path\n",
        ")\n",
        "with open(cfg_json, \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "csv_exists = os.path.exists(log_csv)\n",
        "with open(log_csv, \"a\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    if not csv_exists:\n",
        "        writer.writerow([\n",
        "            \"timestamp\",\"run_name\",\"phase\",\"epoch\",\"train_loss\",\n",
        "            \"train_acc\",\"val_acc\",\"best_val_acc\",\"notes\"\n",
        "        ])\n",
        "        f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "    # log the static params row (phase=meta)\n",
        "    writer.writerow([time.strftime(\"%Y-%m-%d %H:%M:%S\"), run_name, \"meta\", -1, \"\", \"\", \"\", \"\",\n",
        "                     json.dumps(bp)])\n",
        "    f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "# ---- 8) Train readout with early stopping, logging every epoch ----\n",
        "best_val = -1.0\n",
        "epochs_no_improve = 0\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(1, max_epochs+1):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for h, y in feat_train_loader:\n",
        "        h, y = h.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = readout(h)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "    train_loss = total_loss / max(1,total)\n",
        "    train_acc  = 100.0 * correct / max(1,total)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    v_correct, v_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for h, y in feat_val_loader:\n",
        "            h, y = h.to(device), y.to(device)\n",
        "            logits = readout(h)\n",
        "            v_correct += (logits.argmax(1) == y).sum().item()\n",
        "            v_total   += y.size(0)\n",
        "    val_acc = 100.0 * v_correct / max(1,v_total)\n",
        "\n",
        "    # log to CSV immediately (robust to interruptions)\n",
        "    with open(log_csv, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            time.strftime(\"%Y-%m-%d %H:%M:%S\"), run_name, \"train\", epoch,\n",
        "            f\"{train_loss:.6f}\", f\"{train_acc:.2f}\", f\"{val_acc:.2f}\",\n",
        "            f\"{max(best_val,0):.2f}\", \"\"\n",
        "        ])\n",
        "        f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "    # early stopping + checkpoint\n",
        "    if val_acc > best_val + 1e-4:\n",
        "        best_val = val_acc\n",
        "        epochs_no_improve = 0\n",
        "        # save best readout weights\n",
        "        torch.save({\"readout_state_dict\": readout.state_dict(),\n",
        "                    \"params\": bp,\n",
        "                    \"val_acc\": best_val,\n",
        "                    \"epoch\": epoch,\n",
        "                    \"config\": cfg},\n",
        "                   ckpt_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            break\n",
        "\n",
        "elapsed = time.time() - start\n",
        "\n",
        "# ---- 9) Load best checkpoint & evaluate on test set; log results ----\n",
        "if os.path.exists(ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    readout.load_state_dict(ckpt[\"readout_state_dict\"])\n",
        "\n",
        "# test evaluation\n",
        "model.eval()\n",
        "t_correct, t_total = 0, 0\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for h, y in feat_test_loader:\n",
        "        h, y = h.to(device), y.to(device)\n",
        "        logits = readout(h)\n",
        "        preds = logits.argmax(1)\n",
        "        t_correct += (preds == y).sum().item()\n",
        "        t_total   += y.size(0)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "all_preds  = np.concatenate(all_preds, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "acc_test   = t_correct / max(1, t_total)\n",
        "\n",
        "# 95% CI (normal approx)\n",
        "se = np.sqrt(acc_test*(1-acc_test)/max(1, t_total))\n",
        "ci_low, ci_high = acc_test - 1.96*se, acc_test + 1.96*se\n",
        "\n",
        "# confusion matrix (and save)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "np.savetxt(cm_csv, cm, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "# final row in CSV\n",
        "with open(log_csv, \"a\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        time.strftime(\"%Y-%m-%d %H:%M:%S\"), run_name, \"test\", -1, \"\",\n",
        "        \"\", f\"{acc_test*100:.2f}\", f\"{best_val:.2f}\",\n",
        "        f\"95%CI: [{ci_low*100:.2f}, {ci_high*100:.2f}] ; ckpt={ckpt_path}\"\n",
        "    ])\n",
        "    f.flush(); os.fsync(f.fileno())\n",
        "\n",
        "print(f\"[FINAL] test_acc = {acc_test*100:.2f}%  (95% CI: {ci_low*100:.2f}, {ci_high*100:.2f})\")\n",
        "print(f\"Best val_acc = {best_val:.2f}% ; elapsed = {elapsed:.1f}s\")\n",
        "print(f\"Log CSV: {log_csv}\")\n",
        "print(f\"Config JSON: {cfg_json}\")\n",
        "print(f\"Best checkpoint: {ckpt_path}\")\n",
        "print(f\"Confusion matrix CSV: {cm_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "lUlMW4TVZ424",
        "outputId": "e0ce0bb7-9baa-40fe-bbc0-8f1df4ac7994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3426667472.py:292: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.\n",
            "  pruner = optuna.pruners.PatientPruner(\n",
            "[I 2025-11-10 20:46:57,672] Using an existing study with name 'oicgs_mnist' instead of creating a new one.\n",
            "[I 2025-11-10 20:48:32,931] Trial 1 finished with value: 0.9072 and parameters: {'m': 0.5611516415334505, 'a1': 0.9507143064099162, 'tau1': 24, 'tau2': 396, 'f': 0.04207988669606638, 'gamma': 0.00029375384576328325}. Best is trial 1 with value: 0.9072.\n",
            "[I 2025-11-10 20:49:58,648] Trial 2 finished with value: 0.9066 and parameters: {'m': 0.13066739238053282, 'a1': 0.8661761457749352, 'tau1': 12, 'tau2': 510, 'f': 0.012087541473056965, 'gamma': 0.0812324508558869}. Best is trial 1 with value: 0.9072.\n",
            "[I 2025-11-10 20:52:11,934] Trial 3 finished with value: 0.9107999999999999 and parameters: {'m': 4.622589001020832, 'a1': 0.21233911067827616, 'tau1': 1, 'tau2': 152, 'f': 0.1648044642797898, 'gamma': 0.0037520558551242854}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 20:53:38,242] Trial 4 finished with value: 0.9052 and parameters: {'m': 0.7309539835912913, 'a1': 0.2912291401980419, 'tau1': 13, 'tau2': 137, 'f': 0.14742753159914673, 'gamma': 0.001256277350380704}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 20:55:09,641] Trial 5 finished with value: 0.9072 and parameters: {'m': 0.8168455894760165, 'a1': 0.7851759613930136, 'tau1': 1, 'tau2': 326, 'f': 2.342384984711291, 'gamma': 0.000137832374550072}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 20:56:21,405] Trial 6 pruned. \n",
            "[I 2025-11-10 20:57:57,211] Trial 7 pruned. \n",
            "[I 2025-11-10 20:59:24,480] Trial 8 pruned. \n",
            "[I 2025-11-10 21:00:38,513] Trial 9 pruned. \n",
            "[I 2025-11-10 21:02:42,977] Trial 10 pruned. \n",
            "[I 2025-11-10 21:04:54,185] Trial 11 finished with value: 0.9107999999999999 and parameters: {'m': 2.88911812563802, 'a1': 0.11233911067827615, 'tau1': 1, 'tau2': 100, 'f': 0.10300279017486862, 'gamma': 0.0023450349094526783}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 21:05:47,608] Trial 12 pruned. \n",
            "[I 2025-11-10 21:07:55,456] Trial 13 finished with value: 0.9107999999999999 and parameters: {'m': 5.021086448616338, 'a1': 0.2855563350250574, 'tau1': 1, 'tau2': 100, 'f': 0.04443870943601859, 'gamma': 0.0007701692910834705}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 21:09:31,331] Trial 14 finished with value: 0.9072 and parameters: {'m': 3.733787021035916, 'a1': 0.01575796408951996, 'tau1': 3, 'tau2': 128, 'f': 9.104501450363076, 'gamma': 0.0019279988489541726}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 21:11:33,587] Trial 15 finished with value: 0.9107999999999999 and parameters: {'m': 3.2532050764675726, 'a1': 0.15416926962142974, 'tau1': 1, 'tau2': 128, 'f': 0.0871462146827131, 'gamma': 0.035160643588263596}. Best is trial 3 with value: 0.9107999999999999.\n",
            "[I 2025-11-10 21:12:55,721] Trial 16 finished with value: 0.9044 and parameters: {'m': 0.34668071436043457, 'a1': 0.0946427287418219, 'tau1': 1, 'tau2': 120, 'f': 0.07802285462780699, 'gamma': 0.00566187946679322}. Best is trial 3 with value: 0.9107999999999999.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best trial #3\n",
            "Test accuracy: 0.9108\n",
            "Params: {'m': 4.622589001020832, 'a1': 0.21233911067827616, 'tau1': 1, 'tau2': 152, 'f': 0.1648044642797898, 'gamma': 0.0037520558551242854}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'VBG_sim_new'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3426667472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0mpin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m mapping_best = build_mapping_from_params(\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0minput_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.133\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3426667472.py\u001b[0m in \u001b[0;36mbuild_mapping_from_params\u001b[0;34m(seq_len, input_scaling, **params)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mcurrent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moICGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0mcurrent_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# exactly 8 samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# pack mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2018154436.py\u001b[0m in \u001b[0;36moICGS\u001b[0;34m(signal, **params)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mVBG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VBG_sim_new\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID_sim_new\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'VBG_sim_new'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST (greyscale) - ONGOING"
      ],
      "metadata": {
        "id": "QoxkZcxrtM1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare MNIST Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def preprocess_image(tensor_img, threshold = 20):\n",
        "    # tensor_img shape: [1, 28, 28], values in [0.0, 1.0]\n",
        "    tensor_img = tensor_img.squeeze(0)\n",
        "    cropped = tensor_img[2:-2,2:-2] # crop the image to size [24,24]\n",
        "    reshaped = cropped.reshape(seq_len,int(576/seq_len)) # seq_len = 8, input_size = 24*24/8 = 72\n",
        "    return reshaped\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: preprocess_image(x))  # shape: [8, 72]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Validation dataset\n",
        "from torch.utils.data import random_split\n",
        "train_size = len(train_dataset) - params[\"val_size\"]\n",
        "train_subset, val_subset = random_split(\n",
        "    train_dataset, [train_size,  params[\"val_size\"]],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "idx_small = torch.randperm(len(train_subset), generator=torch.Generator().manual_seed(42))[:params[\"train_size\"]]\n",
        "train_subset_small = Subset(train_subset, idx_small)\n",
        "train_loader_local = DataLoader(train_subset_small, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader         = DataLoader(val_subset,   batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "xptxMeEUtOzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def oICGS(signal, **params):\n",
        "    # ---------- Unpack & constants ----------\n",
        "    f       = float(params[\"f\"])\n",
        "    t_ox1   = float(params[\"t_ox1\"])\n",
        "    t_ox2   = float(params[\"t_ox2\"])\n",
        "    eps_ox1 = float(params[\"eps_ox1\"])\n",
        "    eps_ox2 = float(params[\"eps_ox2\"])\n",
        "    m       = float(params[\"m\"])\n",
        "    A       = float(params[\"A\"])  # not used below but kept for completeness\n",
        "    a1      = float(params[\"a1\"])\n",
        "    a2      = 1.0 - a1\n",
        "    tau1    = float(params[\"tau1\"])\n",
        "    tau2    = float(params[\"tau2\"])\n",
        "    Vshift  = float(params[\"V_shift\"])\n",
        "    gamma   = float(params[\"gamma\"])\n",
        "\n",
        "    VBG     = np.asarray(params[\"VBG_sim_new\"])\n",
        "    ID      = np.asarray(params[\"ID_sim_new\"])\n",
        "    signal  = np.asarray(signal, dtype=np.float64)\n",
        "\n",
        "    N       = signal.size\n",
        "    time    = np.linspace(0.0, N / f, N, dtype=np.float64)\n",
        "    dt      = (time[1] - time[0]) if N > 1 else 0.0\n",
        "\n",
        "    # --- Interfacial charge is linear in Vp: sigma = Vp * K_sigma ---\n",
        "    denom   = (t_ox1 + m * t_ox2)\n",
        "    K_sigma = (-eps_ox1 + m * eps_ox2) / denom                 # so sigma_saturate = K_sigma * Vp\n",
        "    # Threshold shift is linear in sigma: ΔVth = K_vth * sigma + Vshift\n",
        "    K_vth   = -t_ox1 / eps_ox1\n",
        "\n",
        "    # Precompute saturation bounds from signal extrema (only 2 evaluations)\n",
        "    Vmax, Vmin = signal.max(initial=0.0), signal.min(initial=0.0)\n",
        "    sig_sat_max = K_sigma * Vmax\n",
        "    sig_sat_min = K_sigma * Vmin\n",
        "    if sig_sat_max > 0 and sig_sat_min > 0:\n",
        "        sigma_saturate_pos, sigma_saturate_neg = max(sig_sat_max, sig_sat_min), 0.0\n",
        "    elif sig_sat_max > 0 and sig_sat_min <= 0:\n",
        "        sigma_saturate_pos, sigma_saturate_neg = sig_sat_max, sig_sat_min\n",
        "    elif sig_sat_max <= 0 and sig_sat_min > 0:\n",
        "        sigma_saturate_pos, sigma_saturate_neg = sig_sat_min, sig_sat_max\n",
        "    else:\n",
        "        sigma_saturate_pos, sigma_saturate_neg = 0.0, min(sig_sat_max, sig_sat_min)\n",
        "\n",
        "    # ---------- Outputs ----------\n",
        "    sigma_generated              = np.zeros(N, dtype=np.float64)\n",
        "    sigma_accumulated            = np.zeros(N+1, dtype=np.float64)  # store one extra leading 0, we’ll use [i]\n",
        "    sigma_accumulated_afterdecay = np.zeros(N+1, dtype=np.float64)  # causal decayed sum state\n",
        "    delta_vth_sigma              = np.zeros(N, dtype=np.float64)\n",
        "    delta_vth_total              = np.zeros(N, dtype=np.float64)\n",
        "    current_index                = np.zeros(N, dtype=np.int64)\n",
        "    current                      = np.zeros(N, dtype=np.float64)\n",
        "\n",
        "    # Initial conditions (Vp = 0 → sigma_initial = 0*K_sigma = 0)\n",
        "    sigma_initial = 0.0  # because K_sigma*0\n",
        "    sigma_accumulated[0] = sigma_initial\n",
        "    sigma_accumulated_afterdecay[0] = 0.0\n",
        "\n",
        "    # ---------- Fast bi-exponential decay via IIR recurrences ----------\n",
        "    # y1[i] = alpha1 * y1[i-1] + x[i]\n",
        "    # y2[i] = alpha2 * y2[i-1] + x[i]\n",
        "    # decayed_sum[i] = a1*y1[i] + a2*y2[i]\n",
        "    if dt > 0.0:\n",
        "        alpha1 = np.exp(-dt / tau1)\n",
        "        alpha2 = np.exp(-dt / tau2)\n",
        "    else:\n",
        "        alpha1 = 0.0\n",
        "        alpha2 = 0.0\n",
        "\n",
        "    y1 = 0.0\n",
        "    y2 = 0.0\n",
        "\n",
        "    for i in range(N):\n",
        "        # running total ΔVth begins with raw signal component\n",
        "        delta_vth_total[i] = float(signal[i])\n",
        "\n",
        "        # saturation target for this step from Vp[i]\n",
        "        sig_sat_i = K_sigma * signal[i]\n",
        "        gen_temp  = sig_sat_i * gamma * dt\n",
        "\n",
        "        # decayed accumulation from previous generated charges:\n",
        "        # (we’ll update y1,y2 AFTER choosing sigma_generated[i] for causality)\n",
        "        decayed_prev = a1 * y1 + a2 * y2\n",
        "        sigma_accumulated_afterdecay[i] = decayed_prev\n",
        "\n",
        "        # enforce saturation bounds by clamping how much we can add\n",
        "        upper_room = sigma_saturate_pos - decayed_prev\n",
        "        lower_room = sigma_saturate_neg - decayed_prev\n",
        "        if gen_temp > upper_room:\n",
        "            gen_i  = upper_room\n",
        "            accum  = sigma_saturate_pos\n",
        "        elif gen_temp < lower_room:\n",
        "            gen_i  = lower_room\n",
        "            accum  = sigma_saturate_neg\n",
        "        else:\n",
        "            gen_i  = gen_temp\n",
        "            accum  = decayed_prev + gen_i\n",
        "\n",
        "        sigma_generated[i]   = gen_i\n",
        "        sigma_accumulated[i] = accum\n",
        "\n",
        "        # update IIR states with the **newly generated** charge at this step\n",
        "        y1 = alpha1 * y1 + gen_i\n",
        "        y2 = alpha2 * y2 + gen_i\n",
        "\n",
        "        # now the *current* decayed sum for index i (after including gen_i)\n",
        "        decayed_now = a1 * y1 + a2 * y2\n",
        "        sigma_accumulated_afterdecay[i] = decayed_now\n",
        "\n",
        "        # ΔVth from sigma (linear)\n",
        "        dvt_sigma = K_vth * sigma_accumulated[i] + Vshift\n",
        "        delta_vth_sigma[i] = dvt_sigma\n",
        "        delta_vth_total[i] += dvt_sigma\n",
        "\n",
        "    # (Optionally drop the extra slot we never filled)\n",
        "    sigma_accumulated = sigma_accumulated[:N]\n",
        "\n",
        "    # ---------- Vectorized nearest index & current ----------\n",
        "    # If VBG is sorted, np.searchsorted would be even faster; otherwise argmin on absolute diff:\n",
        "    # Build [N x len(VBG)] differences without a Python loop:\n",
        "    diffs = np.abs(delta_vth_total[:, None] - VBG[None, :])\n",
        "    current_index = diffs.argmin(axis=1)\n",
        "    current = ID[current_index]\n",
        "\n",
        "    return [sigma_generated, sigma_accumulated, delta_vth_sigma, delta_vth_total, current]\n",
        "\n",
        "'''\n",
        "def oICGS(signal,**params):\n",
        "\n",
        "    def interfacial_charge(Vp, **params):\n",
        "        try:\n",
        "          m      = params[\"m\"]\n",
        "          t_ox1  = params[\"t_ox1\"]\n",
        "          t_ox2  = params[\"t_ox2\"]\n",
        "          eps_ox1= params[\"eps_ox1\"]\n",
        "          eps_ox2= params[\"eps_ox2\"]\n",
        "          A      = params[\"A\"]\n",
        "        except KeyError as e:\n",
        "          raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "        E_ox1 = Vp / (t_ox1 + m * t_ox2)\n",
        "        E_ox2 = m * Vp / (t_ox1 + m * t_ox2)\n",
        "        sigma = - eps_ox1 * E_ox1 + eps_ox2 * E_ox2\n",
        "        return [E_ox1, E_ox2, sigma]\n",
        "\n",
        "    def decay_func(t,**params):\n",
        "      try:\n",
        "        a1 = params[\"a1\"]\n",
        "        a2 = 1-a1\n",
        "        tau1 = params[\"tau1\"]\n",
        "        tau2 = params[\"tau2\"]\n",
        "      except KeyError as e:\n",
        "        raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "      return a1*np.exp(-t/tau1)+a2*np.exp(-t/tau2)\n",
        "\n",
        "    def threshold_shift(sigma, Vshift, **params):\n",
        "      try:\n",
        "        t_ox = params[\"t_ox1\"]\n",
        "        eps_ox = params[\"eps_ox1\"]\n",
        "      except KeyError as e:\n",
        "        raise KeyError(f\"Missing required parameter: {e.args[0]}\")\n",
        "\n",
        "      return -sigma * t_ox/eps_ox + Vshift\n",
        "\n",
        "    def find_index(x,array):\n",
        "        diff_array = np.absolute(np.asarray(array)-x)\n",
        "        index = diff_array.argmin()\n",
        "        return index\n",
        "\n",
        "\n",
        "    f = params[\"f\"]\n",
        "    time = np.linspace(0,len(signal)/f,len(signal))\n",
        "    VBG = params[\"VBG_sim_new\"]\n",
        "    ID = params[\"ID_sim_new\"]\n",
        "    gamma = params[\"gamma\"]\n",
        "\n",
        "    #Initialization\n",
        "    if len(time)>1:\n",
        "        t_interval = time[1]-time[0]\n",
        "    else:\n",
        "        t_interval = 0\n",
        "    sigma_initial = interfacial_charge(Vp = 0, **params)[2]\n",
        "    sigma_accumulated = [sigma_initial]\n",
        "    sigma_accumulated_afterdecay = [0]\n",
        "    sigma_generated = []\n",
        "    delta_vth_sigma = []\n",
        "    delta_vth_total = []\n",
        "    sigma_saturate = []\n",
        "    sigma_generated_temp = []\n",
        "    current_index = []\n",
        "    current = []\n",
        "\n",
        "    #Set threshold\n",
        "    signal_max, signal_min = max(signal), min(signal)\n",
        "    sigma_saturate_max, sigma_saturate_min = interfacial_charge(Vp = signal_max, **params)[2], interfacial_charge(Vp = signal_min, **params)[2]\n",
        "\n",
        "    if sigma_saturate_max>0 and sigma_saturate_min>0:\n",
        "        sigma_saturate_pos = max(sigma_saturate_max, sigma_saturate_min)\n",
        "        sigma_saturate_neg = 0\n",
        "    elif sigma_saturate_max >0 and sigma_saturate_min <=0:\n",
        "        sigma_saturate_pos = sigma_saturate_max\n",
        "        sigma_saturate_neg = sigma_saturate_min\n",
        "    elif sigma_saturate_max <=0 and sigma_saturate_min >0:\n",
        "        sigma_saturate_pos = sigma_saturate_min\n",
        "        sigma_saturate_neg = sigma_saturate_max\n",
        "    else:\n",
        "        sigma_saturate_pos = 0\n",
        "        sigma_saturate_neg = min(sigma_saturate_max, sigma_saturate_min)\n",
        "\n",
        "    # Calculate charge\n",
        "    for i in range(len(time)):\n",
        "        delta_vth_total.append(float(signal[i]))\n",
        "        sigma_saturate.append(interfacial_charge(Vp = signal[i], **params)[2])\n",
        "        sigma_generated_temp.append(sigma_saturate[i]*gamma*t_interval)\n",
        "\n",
        "        if sigma_accumulated_afterdecay[i]+sigma_generated_temp[i] > sigma_saturate_pos:\n",
        "            sigma_generated.append(sigma_saturate_pos-sigma_accumulated_afterdecay[i])\n",
        "            sigma_accumulated.append(sigma_saturate_pos)\n",
        "\n",
        "        elif sigma_accumulated_afterdecay[i]+sigma_generated_temp[i] < sigma_saturate_neg:\n",
        "            sigma_generated.append(sigma_saturate_neg-sigma_accumulated_afterdecay[i])\n",
        "            sigma_accumulated.append(sigma_saturate_neg)\n",
        "\n",
        "        else:\n",
        "            sigma_generated.append(sigma_generated_temp[i])\n",
        "            sigma_accumulated.append(sigma_accumulated_afterdecay[i]+sigma_generated[i])\n",
        "\n",
        "        sigma_accumulated_afterdecay_temp = 0\n",
        "        for j in range(len(sigma_generated)):\n",
        "            sigma_accumulated_afterdecay_temp += sigma_generated[j]*decay_func(time[i]-time[j], **params)\n",
        "        sigma_accumulated_afterdecay.append(sigma_accumulated_afterdecay_temp)\n",
        "\n",
        "        # Calculate threshold voltage shift and current\n",
        "        delta_vth_sigma.append(threshold_shift(sigma_accumulated[i],Vshift = params[\"V_shift\"],**params))\n",
        "        delta_vth_total[i] += threshold_shift(sigma_accumulated[i],Vshift = params[\"V_shift\"],**params)\n",
        "        current_index.append(find_index(delta_vth_total[i],VBG))\n",
        "        current.append(ID[find_index(delta_vth_total[i],VBG)])\n",
        "\n",
        "    return [sigma_generated,sigma_accumulated,delta_vth_sigma,delta_vth_total,current]\n",
        "\n",
        "params = {\n",
        "    \"eps_ox1\": 3.45e-11, #F/m\n",
        "    \"eps_ox2\": 1.33e-10, #F/m\n",
        "    \"C_ox1\": 3.45e-3, #F/m\n",
        "    \"C_ox2\": 1.33e-2, #F/m\n",
        "    \"t_ox1\": 1e-8, #m\n",
        "    \"t_ox2\": 1e-8, #m\n",
        "    \"W\": 1.5e-5, #m\n",
        "    \"L\": 5e-7, #m\n",
        "    \"A\": 7.5e-12, #m^2\n",
        "    \"V_p\": -4, #V\n",
        "    \"V_ds\": 1e-2, #V\n",
        "     \"V_shift\": 0, #V\n",
        "    \"V_FB\": -0.95, #V\n",
        "    \"n_e\": 1.5, #a.u.\n",
        "    \"m\": 0.9, #a.u.\n",
        "    \"a1\": 0.72, #a.u., a2 = 1-a1\n",
        "    \"tau1\": 4, #s\n",
        "    \"tau2\": 506, #s\n",
        "    \"f\": 0.025, #Hz\n",
        "    \"N_digits\": 8, #a.u.\n",
        "    \"VBG_sim_new\": VBG_sim_new,\n",
        "    \"ID_sim_new\": ID_sim_new,\n",
        "    \"VBG_exp\": b_vg_exp,\n",
        "    \"ID_exp\": b_id_exp,\n",
        "    \"gamma\": 0.00203,\n",
        "    \"rho\": 1,\n",
        "    \"val_size\":5000, # Validation set\n",
        "    \"train_size\": 60000, # Smaller training set for fast training\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.0001,\n",
        "    \"scaling\": 1e7,\n",
        "    \"mapping\": mapping, # For original ICGS\n",
        "}\n",
        "'''\n",
        "params = {\n",
        "    \"eps_ox1\": 3.45e-11, #F/m\n",
        "    \"eps_ox2\": 1.33e-10, #F/m\n",
        "    \"C_ox1\": 3.45e-3, #F/m\n",
        "    \"C_ox2\": 1.33e-2, #F/m\n",
        "    \"t_ox1\": 1e-8, #m\n",
        "    \"t_ox2\": 1e-8, #m\n",
        "    \"W\": 1.5e-5, #m\n",
        "    \"L\": 5e-7, #m\n",
        "    \"A\": 7.5e-12, #m^2\n",
        "    \"V_p\": 4, #V\n",
        "    \"V_ds\": 1e-2, #V\n",
        "     \"V_shift\": -1.5, #V\n",
        "    \"V_FB\": -0.95, #V\n",
        "    \"n_e\": 1.5, #a.u.\n",
        "    \"m\": 0.2, #a.u.\n",
        "    \"a1\": 0.8, #a.u., a2 = 1-a1\n",
        "    \"tau1\": 10, #s\n",
        "    \"tau2\": 506, #s\n",
        "    \"f\": 0.2, #Hz\n",
        "    \"N_digits\": 8, #a.u.\n",
        "    \"VBG_sim_new\": VBG_sim_new,\n",
        "    \"ID_sim_new\": ID_sim_new,\n",
        "    \"VBG_exp\": b_vg_exp,\n",
        "    \"ID_exp\": b_id_exp,\n",
        "    \"gamma\": 0.00203,\n",
        "    \"rho\": 1,\n",
        "    \"val_size\":5000, # Validation set\n",
        "    \"train_size\": 60000, # Smaller training set for fast training\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.0001,\n",
        "    \"scaling\": 1e7,\n",
        "    \"mapping\": mapping, # For original ICGS\n",
        "}\n",
        "'''\n",
        "num_epochs = params[\"num_epochs\"]\n",
        "batch_size = params[\"batch_size\"]\n",
        "lr = params[\"lr\"]\n",
        "seq_len = 8\n",
        "input_size = int(576/seq_len)\n",
        "\n",
        "class ICGSReservoirLayer(nn.Module):\n",
        "    def __init__(self, input_size:int, seq_len:int, **params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.batch_size = params.get(batch_size)\n",
        "        self.input_size = input_size\n",
        "        self.seq_len = seq_len\n",
        "        self.f = self.params.get(\"f\")\n",
        "        self.t_RC = np.linspace(0, self.seq_len/self.f,self.seq_len)\n",
        "        self.V_p = self.params.get(\"V_p\")\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.size(0) # Get batch size from input tensor\n",
        "        device = x.device\n",
        "\n",
        "        # Initial reservoir state\n",
        "        h_t = torch.zeros(batch_size*self.input_size, self.seq_len, device=device)\n",
        "\n",
        "        x = x.permute(0, 2, 1)  # [batch, input, seq_len]\n",
        "        x = x.reshape(-1, self.seq_len)  # [batch * input, seq_len]\n",
        "        x = torch.mul(x, self.V_p)\n",
        "\n",
        "        for index in range(x.size(0)):\n",
        "            current = oICGS(x[index, :].tolist(), **self.params)[4]\n",
        "            current_tensor = torch.tensor(current, device=device)\n",
        "            h_t[index, :] = current_tensor\n",
        "\n",
        "        h_t = h_t.reshape(batch_size, self.input_size, self.seq_len).permute(0, 2, 1) #[batch, seq_len, input]\n",
        "        return h_t*self.params.get(\"scaling\")  # Final reservoir state used for classification\n",
        "\n",
        "class ICGSReservoirNet(nn.Module):\n",
        "    def __init__(self, input_size, seq_len, output_size, **params):\n",
        "        super().__init__()\n",
        "        self.reservoir = ICGSReservoirLayer(input_size, seq_len, **params)\n",
        "        # Normalization\n",
        "        self.bn = nn.BatchNorm1d(seq_len*input_size)\n",
        "        # test on nonlinear projection\n",
        "        self.readout = nn.Linear(seq_len*input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        reservoir_state = self.reservoir(x)\n",
        "        reservoir_state_reshaped = torch.reshape(reservoir_state, (reservoir_state.size(dim=0), reservoir_state.size(dim=1)*reservoir_state.size(dim=2)))\n",
        "        reservoir_state_norm = self.bn(reservoir_state_reshaped)\n",
        "        out = self.readout(reservoir_state_norm)\n",
        "\n",
        "        #out = self.readout(reservoir_state_reshaped)\n",
        "        return out"
      ],
      "metadata": {
        "id": "qQG_L4ixvTj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reservoir function check"
      ],
      "metadata": {
        "id": "ahvT7eSIAPlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of data from the test_loader\n",
        "x, y = next(iter(test_loader))\n",
        "\n",
        "# Select the first image in the batch and move it to CPU for plotting\n",
        "figure_example = x[1].cpu().numpy()\n",
        "figure_flattened = figure_example.reshape(-1)\n",
        "\n",
        "# Reshape the image back to 24x24 for plotting\n",
        "reshaped_image = figure_example.reshape(24, 24)\n",
        "\n",
        "# Plot the original image\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(reshaped_image, cmap='gray')\n",
        "plt.title(f\"Original Image (Label: {y[1].item()})\")\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "\n",
        "# Calculate state signals for each input sequence\n",
        "state_signals = []\n",
        "for i in range(input_size):\n",
        "    current_signal = oICGS(figure_flattened[i*seq_len:i*seq_len+seq_len].tolist(), **params)[4]\n",
        "    state_signals.extend(current_signal) # Use extend to flatten the list\n",
        "\n",
        "# Convert the list of state signals to a numpy array for easier handling\n",
        "state_signals_np = np.array(state_signals)\n",
        "\n",
        "# Reshape the state signals to 24x24 for displaying as an image\n",
        "state_signals_image = state_signals_np.reshape(24, 24)\n",
        "print(state_signals_image)\n",
        "\n",
        "# Plot the state signals as an image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(state_signals_image, cmap='gray')\n",
        "plt.title(\"State Signals as Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G1BaS5ZwAIwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ICG_model = ICGSReservoirNet(input_size = input_size, seq_len = seq_len, output_size=10, **params).to(device)\n",
        "optimizer = torch.optim.Adam(ICG_model.readout.parameters(), lr=lr)  # Only train readout\n",
        "\n",
        "loss_train_hist = []\n",
        "acc_train_hist = []\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    ICG_model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in train_loader_local:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = ICG_model(x)\n",
        "        output = F.log_softmax(output,dim =1)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    loss_train_hist.append(total_loss)\n",
        "    acc_train_hist.append(acc)\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "end_time = time.time()\n",
        "t_total = end_time - start_time\n",
        "t_per_epoch = t_total / num_epochs\n",
        "\n",
        "print(f\"Total training time: {t_total:.2f} seconds\")\n",
        "print(f\"Training time per epoch: {t_per_epoch:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "uACgxWhxtpR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "ICG_model.eval()  # set model to evaluation mode\n",
        "tic = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = ICG_model(x)\n",
        "        preds = output.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "# Inference time\n",
        "t_inf = time.time()-tic\n",
        "\n",
        "# Accuracy\n",
        "acc_test = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {acc_test * 100:.2f}% | Inference time: {t_inf:.2f} seconds\")\n",
        "\n",
        "# Accuracy (95% Confidence Interval)\n",
        "SE_test = np.sqrt(acc_test * (1 - acc_test) / len(all_labels))\n",
        "z_score = 1.96  # 95% confidence interval\n",
        "CI_test = (acc_test - z_score * SE_test, acc_test + z_score * SE_test)\n",
        "print(f\"Test Accuracy (95% CI): {CI_test[0]*100:.2f}% - {CI_test[1]*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "append_run_log(\n",
        "    LOG_PATH,\n",
        "    params=params,\n",
        "    seq_len=seq_len,\n",
        "    input_size=input_size,\n",
        "    loss_train_per_epoch=loss_train_hist,\n",
        "    acc_train_per_epoch=acc_train_hist,\n",
        "    t_tot=t_total,\n",
        "    t_per_epoch=t_per_epoch,\n",
        "    acc_test=acc_test,\n",
        "    acc_test_95CI_low=CI_test[0],\n",
        "    acc_test_95CI_high=CI_test[1],\n",
        "    t_inf=t_inf,\n",
        ")"
      ],
      "metadata": {
        "id": "kDmaYoZs41CE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}